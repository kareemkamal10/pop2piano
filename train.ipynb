{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Pop2Piano - Training Pipeline ðŸŽ¹\n",
        "\n",
        "## Upgraded Version (2026)\n",
        "\n",
        "This notebook trains the Pop2Piano model with:\n",
        "- **Mixed Precision (FP16)** - 2x faster training\n",
        "- **Gradient Checkpointing** - 40% less memory\n",
        "- **Maqam-Aware Training** - Tokens = Ù…Ù‚Ø§Ù…Ø§Øª (Ø±Ø§Ø³ØªØŒ Ø­Ø¬Ø§Ø²ØŒ Ø¨ÙŠØ§ØªÙŠ...) + western\n",
        "- **Piano Rules** - Better playability\n",
        "- **Resume from Checkpoint** - Continue if interrupted\n",
        "- **Fine-tune Mode** - Mixed Arabic + English data, lower LR, fewer epochs\n",
        "\n",
        "## Steps:\n",
        "1. **Setup** - Install dependencies\n",
        "2. **Clone** - Get latest code\n",
        "3. **Download** - Get training data (train_dataset.csv and/or arabic_dataset.csv)\n",
        "4. **Preprocess** - Prepare audio/MIDI pairs (align, beat quantize, etc.)\n",
        "5. **Detect Maqam** - Run `preprocess_maqam.py` to tag each track with maqam\n",
        "6. **Train** - Run training loop (full training or fine-tune)\n",
        "7. **Test** - Benchmark results"
      ],
      "id": "f5fed6eb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# @title 1. Mount Google Drive ðŸ’¾\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create a persistent working directory in your Google Drive\n",
        "GDRIVE_WORKING_DIR = \"/content/drive/MyDrive/Pop2Piano_Workspace\"\n",
        "if not os.path.exists(GDRIVE_WORKING_DIR):\n",
        "    os.makedirs(GDRIVE_WORKING_DIR)\n",
        "\n",
        "# Change to the persistent directory\n",
        "%cd {GDRIVE_WORKING_DIR}\n",
        "\n",
        "print(f\"Switched to persistent directory: {os.getcwd()}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "abf775bf"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# @title 2. Install Dependencies ðŸ“¦ (Updated 2026)\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "print(\"ðŸ”§ Installing updated dependencies...\")\n",
        "\n",
        "# Core ML Libraries (PyTorch 2.x with CUDA)\n",
        "!pip install -q torch>=2.1.0 torchaudio>=2.1.0 --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "# Transformers and Lightning (latest)\n",
        "!pip install -q transformers>=4.40.0 lightning>=2.2.0\n",
        "\n",
        "# Audio Processing\n",
        "!pip install -q librosa>=0.10.0 soundfile>=0.12.0 pretty_midi>=0.2.10 note-seq pyFluidSynth\n",
        "\n",
        "# Configuration & Utilities\n",
        "!pip install -q omegaconf>=2.3.0 numba>=0.58.0 scipy>=1.11.0\n",
        "\n",
        "# Training Utilities\n",
        "!pip install -q tensorboard>=2.15.0 wandb>=0.16.0\n",
        "\n",
        "# Data Processing\n",
        "!pip install -q pandas tqdm yt-dlp imageio-ffmpeg\n",
        "\n",
        "# System packages\n",
        "!apt-get update -q && apt-get install -y -q fluidsynth fluid-soundfont-gm ffmpeg\n",
        "\n",
        "print(\"âœ… All dependencies installed!\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "36a7d37e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# @title 3. Setup Essentia (for rhythm extraction) ðŸª„\n",
        "import sys\n",
        "\n",
        "# Try to install essentia, otherwise mock it\n",
        "try:\n",
        "    !pip install -q essentia-tensorflow\n",
        "    import essentia\n",
        "    print(\"âœ… Essentia installed successfully!\")\n",
        "except:\n",
        "    print(\"âš ï¸ Essentia installation failed. Using mock...\")\n",
        "    from unittest.mock import MagicMock\n",
        "    from importlib.machinery import ModuleSpec\n",
        "    \n",
        "    mock_essentia = MagicMock()\n",
        "    mock_essentia.__spec__ = ModuleSpec(name='essentia', loader=None)\n",
        "    \n",
        "    sys.modules[\"essentia\"] = mock_essentia\n",
        "    sys.modules[\"essentia.standard\"] = MagicMock()\n",
        "    \n",
        "    print(\"âœ… Essentia mocked successfully!\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "6fa6e575"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# @title 4. Clone Repository ðŸ™\n",
        "import os\n",
        "\n",
        "repo_url = \"https://github.com/kareemkamal10/pop2piano.git\"\n",
        "repo_name = \"pop2piano\"\n",
        "branch = \"upgradeProject\"  # Use the upgraded branch with new features\n",
        "\n",
        "if os.path.exists(repo_name):\n",
        "    print(\"Repository already cloned. Pulling latest changes...\")\n",
        "    %cd {repo_name}\n",
        "    !git fetch origin\n",
        "    !git checkout {branch}\n",
        "    !git pull origin {branch}\n",
        "else:\n",
        "    print(f\"Cloning {repo_url} (branch: {branch})...\")\n",
        "    !git clone -b {branch} {repo_url}\n",
        "    %cd {repo_name}\n",
        "\n",
        "print(f\"\\nâœ… Current directory: {os.getcwd()}\")\n",
        "print(f\"ðŸ“Œ Branch: {branch}\")\n",
        "\n",
        "# Verify new files exist\n",
        "new_files = ['piano_rules.py', 'arabic_maqamat.py', 'benchmark.py']\n",
        "for f in new_files:\n",
        "    status = \"âœ…\" if os.path.exists(f) else \"âŒ\"\n",
        "    print(f\"   {status} {f}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "6df69f0e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# @title 4. Run Download Script (CLI / Background Mode) ðŸ“¥\n",
        "# Runs in background, logs to download_log.txt.\n",
        "# Limit: 50 MB for testing â€” change to 15.0 or more for full training.\n",
        "\n",
        "MAX_SIZE_MB = 50   # Test run: 50 MB max. Full run: e.g. 15360 for 15 GB\n",
        "max_size_gb = MAX_SIZE_MB / 1024.0\n",
        "\n",
        "print(\"Starting download (max size: {} MB for testing)...\".format(MAX_SIZE_MB))\n",
        "print(\"Logs: download_log.txt. Run the NEXT cell to check progress.\")\n",
        "\n",
        "!python download/download.py train_dataset.csv output_dir/ --max_size_gb {max_size_gb} > download_log.txt 2>&1\n",
        "\n",
        "print(\"Done.\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "29258db9"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# @title 4.1 Monitor Progress (Live Log View) ðŸ“º\n",
        "# Run this cell anytime to see the last 20 lines of the download process.\n",
        "# Similar to tailing a log in Linux.\n",
        "\n",
        "!tail -n 20 download_log.txt\n",
        "\n",
        "# Or to follow it live for a few seconds (uncomment below):\n",
        "# !timeout 10 tail -f download_log.txt"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "fd8fe2b4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. Detect Maqam (Maqam-Aware Training)\n",
        "\n",
        "Run this **after** preprocessing (align, bpm_quantize) and **before** training.  \n",
        "It writes a `.maqam.txt` per track so the dataset uses the correct maqam token."
      ],
      "id": "95de1e6c"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# @title 5.1 Run Maqam Detection\n",
        "import os\n",
        "\n",
        "DATA_DIR_FOR_MAQAM = \"output_dir\"  # Same as your preprocessed data dir\n",
        "\n",
        "if os.path.exists(DATA_DIR_FOR_MAQAM):\n",
        "    !python preprocess/preprocess_maqam.py {DATA_DIR_FOR_MAQAM}\n",
        "    print(\"Done. Each track now has a .maqam.txt file (e.g. hijaz, western).\")\n",
        "else:\n",
        "    print(\"Skip: DATA_DIR not found. Run download + preprocess first.\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "44f1e6cc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# @title 6. Start Training (Full or Fine-Tune)\n",
        "import os\n",
        "\n",
        "# Data\n",
        "DATA_DIR = \"output_dir\"  # Preprocessed data (run preprocess_maqam.py first for maqam-aware)\n",
        "\n",
        "# Mode: fine-tune = Arabic + English mix, lower LR, fewer epochs; full = train from scratch\n",
        "FINE_TUNE = True         # True: use lower LR and fewer epochs, optionally --resume from pretrained\n",
        "PRECISION = \"16-mixed\"   # 32, 16-mixed, bf16-mixed\n",
        "BATCH_SIZE = 8           # Colab T4: 8, A100: 32\n",
        "\n",
        "# Full training (from scratch)\n",
        "EPOCHS_FULL = 100\n",
        "LR_FULL = 0.001\n",
        "\n",
        "# Fine-tune (maqam-aware, mixed Arabic + English)\n",
        "EPOCHS_FINETUNE = 80\n",
        "LR_FINETUNE = 0.0001\n",
        "RESUME = None            # Path to checkpoint (e.g. sweetcocoa/pop2piano weights or last.ckpt)\n",
        "\n",
        "if FINE_TUNE:\n",
        "    EPOCHS, LR = EPOCHS_FINETUNE, LR_FINETUNE\n",
        "    print(\"Mode: Fine-tune (maqam-aware, mixed data)\")\n",
        "else:\n",
        "    EPOCHS, LR = EPOCHS_FULL, LR_FULL\n",
        "    print(\"Mode: Full training\")\n",
        "\n",
        "if not os.path.exists(DATA_DIR) or len(os.listdir(DATA_DIR)) == 0:\n",
        "    print(\"No data in output_dir. Run download + preprocess + maqam detection first.\")\n",
        "else:\n",
        "    cmd = f\"python train.py --data_dir {DATA_DIR} --precision {PRECISION} --epochs {EPOCHS} --batch_size {BATCH_SIZE} --lr {LR}\"\n",
        "    if RESUME:\n",
        "        cmd += f\" --resume {RESUME}\"\n",
        "    print(f\"Tracks: {len(os.listdir(DATA_DIR))}, epochs={EPOCHS}, lr={LR}\")\n",
        "    !{cmd}\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [],
      "id": "40d66024"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# @title 7. Benchmark & Test ðŸ“Š\n",
        "# Run this to test the piano rules and Arabic maqamat\n",
        "\n",
        "print(\"ðŸŽ¹ Running benchmark demo...\\n\")\n",
        "!python benchmark.py --demo\n",
        "\n",
        "# Display generated images\n",
        "from IPython.display import Image, display\n",
        "\n",
        "print(\"\\nðŸ“Š Piano Roll Comparison (Before/After Rules):\")\n",
        "display(Image('benchmark_piano_roll.png'))\n",
        "\n",
        "print(\"\\nðŸ“Š Note Distribution:\")\n",
        "display(Image('benchmark_distribution.png'))\n",
        "\n",
        "print(\"\\nðŸŽµ Maqam Quantization Demo:\")\n",
        "display(Image('benchmark_maqam.png'))"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "5408a0fd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# @title 8. Arabic Maqamat Demo ðŸŽµ\n",
        "# Visualize all available Arabic maqamat\n",
        "\n",
        "print(\"ðŸŽµ Arabic Maqamat Visualization...\\n\")\n",
        "!python benchmark.py --maqam-demo\n",
        "\n",
        "from IPython.display import Image, display\n",
        "display(Image('maqamat_scales.png'))\n",
        "\n",
        "# List all maqamat\n",
        "from arabic_maqamat import list_all_maqamat\n",
        "\n",
        "print(\"\\nðŸ“œ Available Maqamat for Inference:\")\n",
        "for m in list_all_maqamat():\n",
        "    print(f\"   â€¢ {m['name_en']:<12} {m['name_ar']:<8} | {m['mood']}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "9f2caa08"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# @title 9. Save Model to Google Drive ðŸ’¾\n",
        "import shutil\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Checkpoint directory\n",
        "CHECKPOINT_DIR = \"checkpoints\"\n",
        "DRIVE_DIR = \"/content/drive/MyDrive/Pop2Piano_Checkpoints\"\n",
        "\n",
        "# Create drive directory if not exists\n",
        "os.makedirs(DRIVE_DIR, exist_ok=True)\n",
        "\n",
        "# Find latest checkpoint\n",
        "if os.path.exists(CHECKPOINT_DIR):\n",
        "    checkpoints = [f for f in os.listdir(CHECKPOINT_DIR) if f.endswith('.ckpt')]\n",
        "    if checkpoints:\n",
        "        # Copy all checkpoints to drive\n",
        "        for ckpt in checkpoints:\n",
        "            src = os.path.join(CHECKPOINT_DIR, ckpt)\n",
        "            dst = os.path.join(DRIVE_DIR, ckpt)\n",
        "            shutil.copy2(src, dst)\n",
        "            print(f\"âœ… Saved: {ckpt}\")\n",
        "        \n",
        "        print(f\"\\nðŸ“ Checkpoints saved to: {DRIVE_DIR}\")\n",
        "    else:\n",
        "        print(\"âŒ No checkpoints found!\")\n",
        "else:\n",
        "    print(\"âŒ Checkpoint directory not found. Train first!\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "a8a6419c"
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}